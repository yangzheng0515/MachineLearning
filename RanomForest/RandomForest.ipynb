{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 项目案例: 声纳信号分类\n",
    "项目完整代码：https://github.com/apachecn/AiLearning/blob/master/src/py3.x/ml/7.RandomForest/randomForest.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed, randrange, random\n",
    "\n",
    "\n",
    "# 导入csv文件\n",
    "def loadDataSet(filename):\n",
    "    dataset = []\n",
    "    with open(filename, 'r') as fr:\n",
    "        for line in fr.readlines():\n",
    "            if not line:\n",
    "                continue\n",
    "            lineArr = []\n",
    "            for featrue in line.split(','):\n",
    "                # strip()返回移除字符串头尾指定的字符生成的新字符串\n",
    "                str_f = featrue.strip()\n",
    "                if str_f.isdigit(): # 判断是否是数字\n",
    "                    # 将数据集的第column列转换成float形式\n",
    "                    lineArr.append(float(str_f))\n",
    "                else:\n",
    "                    # 添加分类标签\n",
    "                    lineArr.append(str_f)\n",
    "            dataset.append(lineArr)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_split(dataset, n_folds):\n",
    "    \"\"\"cross_validation_split(将数据集进行抽重抽样 n_folds 份，数据可以重复抽取)\n",
    "\n",
    "    Args:\n",
    "        dataset     原始数据集\n",
    "        n_folds     数据集dataset分成n_flods份\n",
    "    Returns:\n",
    "        dataset_split    list集合，存放的是：将数据集进行抽重抽样 n_folds 份，数据可以重复抽取\n",
    "    \"\"\"\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)       # 复制一份 dataset,防止 dataset 的内容改变\n",
    "    fold_size = len(dataset) / n_folds\n",
    "    for i in range(n_folds):\n",
    "        fold = list()                  # 每次循环 fold 清零，防止重复导入 dataset_split\n",
    "        while len(fold) < fold_size:   # 这里不能用 if，if 只是在第一次判断时起作用，while 执行循环，直到条件不成立\n",
    "            # 有放回的随机采样，有一些样本被重复采样，从而在训练集中多次出现，有的则从未在训练集中出现，此为自助采样法。从而保证每棵决策树训练集的差异性            \n",
    "            index = randrange(len(dataset_copy))\n",
    "            # 将对应索引 index 的内容从 dataset_copy 中导出，并将该内容从 dataset_copy 中删除。\n",
    "            # pop() 函数用于移除列表中的一个元素（默认最后一个元素），并且返回该元素的值。\n",
    "            fold.append(dataset_copy.pop(index))  # 无放回的方式\n",
    "            # fold.append(dataset_copy[index])  # 有放回的方式\n",
    "        dataset_split.append(fold)\n",
    "    # 由dataset分割出的n_folds个数据构成的列表，为了用于交叉验证\n",
    "    return dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random subsample from the dataset with replacement\n",
    "def subsample(dataset, ratio):   # 创建数据集的随机子样本\n",
    "    \"\"\"random_forest(评估算法性能，返回模型得分)\n",
    "\n",
    "    Args:\n",
    "        dataset         训练数据集\n",
    "        ratio           训练数据集的样本比例\n",
    "    Returns:\n",
    "        sample          随机抽样的训练样本\n",
    "    \"\"\"\n",
    "\n",
    "    sample = list()\n",
    "    # 训练样本的按比例抽样。\n",
    "    # round() 方法返回浮点数x的四舍五入值。\n",
    "    n_sample = round(len(dataset) * ratio)\n",
    "    while len(sample) < n_sample:\n",
    "        # 有放回的随机采样，有一些样本被重复采样，从而在训练集中多次出现，有的则从未在训练集中出现，此为自助采样法。从而保证每棵决策树训练集的差异性\n",
    "        index = randrange(len(dataset))\n",
    "        sample.append(dataset[index])\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找出分割数据集的最优特征，得到最优的特征 index，特征值 row[index]，以及分割完的数据 groups（left, right）\n",
    "def get_split(dataset, n_features):\n",
    "    class_values = list(set(row[-1] for row in dataset))  # class_values =[0, 1]\n",
    "    b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "    features = list()\n",
    "    while len(features) < n_features:\n",
    "        index = randrange(len(dataset[0])-1)  # 往 features 添加 n_features 个特征（ n_feature 等于特征数的个数），特征索引从 dataset 中随机取\n",
    "        if index not in features:\n",
    "            features.append(index)\n",
    "    for index in features:                    # 在 n_features 个特征中选出最优的特征索引，并没有遍历所有特征，从而保证了每课决策树的差异性\n",
    "        for row in dataset:\n",
    "            groups = test_split(index, row[index], dataset)  # groups=(left, right), row[index] 遍历每一行 index 索引下的特征值作为分类值 value, 找出最优的分类特征和特征值\n",
    "            gini = gini_index(groups, class_values)\n",
    "            # 左右两边的数量越一样，说明数据区分度不高，gini系数越大\n",
    "            if gini < b_score:\n",
    "                b_index, b_value, b_score, b_groups = index, row[index], gini, groups  # 最后得到最优的分类特征 b_index,分类特征值 b_value,分类结果 b_groups。b_value 为分错的代价成本\n",
    "    # print b_score\n",
    "    return {'index': b_index, 'value': b_value, 'groups': b_groups}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Algorithm\n",
    "def random_forest(train, test, max_depth, min_size, sample_size, n_trees, n_features):\n",
    "    \"\"\"random_forest(评估算法性能，返回模型得分)\n",
    "\n",
    "    Args:\n",
    "        train           训练数据集\n",
    "        test            测试数据集\n",
    "        max_depth       决策树深度不能太深，不然容易导致过拟合\n",
    "        min_size        叶子节点的大小\n",
    "        sample_size     训练数据集的样本比例\n",
    "        n_trees         决策树的个数\n",
    "        n_features      选取的特征的个数\n",
    "    Returns:\n",
    "        predictions     每一行的预测结果，bagging 预测最后的分类结果\n",
    "    \"\"\"\n",
    "\n",
    "    trees = list()\n",
    "    # n_trees 表示决策树的数量\n",
    "    for i in range(n_trees):\n",
    "        # 随机抽样的训练样本， 随机采样保证了每棵决策树训练集的差异性\n",
    "        sample = subsample(train, sample_size)\n",
    "        # 创建一个决策树\n",
    "        tree = build_tree(sample, max_depth, min_size, n_features)\n",
    "        trees.append(tree)\n",
    "\n",
    "    # 每一行的预测结果，bagging 预测最后的分类结果\n",
    "    predictions = [bagging_predict(trees, row) for row in test]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估算法性能，返回模型得分\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "    \"\"\"evaluate_algorithm(评估算法性能，返回模型得分)\n",
    "\n",
    "    Args:\n",
    "        dataset     原始数据集\n",
    "        algorithm   使用的算法\n",
    "        n_folds     数据的份数\n",
    "        *args       其他的参数\n",
    "    Returns:\n",
    "        scores      模型得分\n",
    "    \"\"\"\n",
    "\n",
    "    # 将数据集进行随机抽样，分成 n_folds 份，数据无重复的抽取\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    scores = list()\n",
    "    # 每次循环从 folds 从取出一个 fold 作为测试集，其余作为训练集，遍历整个 folds ，实现交叉验证\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        # 将多个 fold 列表组合成一个 train_set 列表, 类似 union all\n",
    "        \"\"\"\n",
    "        In [20]: l1=[[1, 2, 'a'], [11, 22, 'b']]\n",
    "        In [21]: l2=[[3, 4, 'c'], [33, 44, 'd']]\n",
    "        In [22]: l=[]\n",
    "        In [23]: l.append(l1)\n",
    "        In [24]: l.append(l2)\n",
    "        In [25]: l\n",
    "        Out[25]: [[[1, 2, 'a'], [11, 22, 'b']], [[3, 4, 'c'], [33, 44, 'd']]]\n",
    "        In [26]: sum(l, [])\n",
    "        Out[26]: [[1, 2, 'a'], [11, 22, 'b'], [3, 4, 'c'], [33, 44, 'd']]\n",
    "        \"\"\"\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = list()\n",
    "        # fold 表示从原始数据集 dataset 提取出来的测试集\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            row_copy[-1] = None \n",
    "            test_set.append(row_copy)\n",
    "        predicted = algorithm(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "\n",
    "        # 计算随机森林的预测结果的正确率\n",
    "        accuracy = accuracy_metric(actual, predicted)\n",
    "        scores.append(accuracy)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
