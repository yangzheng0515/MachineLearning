{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 项目案例1: 判定鱼类和非鱼类\n",
    "\n",
    "from: https://ailearning.apachecn.org/#/docs/ml/3.DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "收集数据：可以使用任何方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataSet():\n",
    "    dataSet = [[1, 1, 'yes'],\n",
    "            [1, 1, 'yes'],\n",
    "            [1, 0, 'no'],\n",
    "            [0, 1, 'no'],\n",
    "            [0, 1, 'no']]\n",
    "    labels = ['no surfacing', 'flippers']\n",
    "    return dataSet, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]\n",
      "['no surfacing', 'flippers']\n"
     ]
    }
   ],
   "source": [
    "myDat, labels = createDataSet()\n",
    "print(myDat)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算给定数据集的香农熵的函数\n",
    "import math\n",
    "def calcShannonEnt(dataSet):\n",
    "    # 求list的长度，表示计算参与训练的数据量\n",
    "    numEntries = len(dataSet)\n",
    "    # 计算分类标签label出现的次数\n",
    "    labelCounts = {}\n",
    "    # the the number of unique elements and their occurrence\n",
    "    for featVec in dataSet:\n",
    "        # 将当前实例的标签存储，即每一行数据的最后一个数据代表的是标签\n",
    "        currentLabel = featVec[-1]\n",
    "        # 为所有可能的分类创建字典，如果当前的键值不存在，则扩展字典并将当前键值加入字典。每个键值都记录了当前类别出现的次数。\n",
    "        if currentLabel not in labelCounts.keys():\n",
    "            labelCounts[currentLabel] = 0\n",
    "        labelCounts[currentLabel] += 1\n",
    "\n",
    "    # 对于 label 标签的占比，求出 label 标签的香农熵\n",
    "    shannonEnt = 0.0\n",
    "    for key in labelCounts:\n",
    "        # 使用所有类标签的发生频率计算类别出现的概率。\n",
    "        prob = float(labelCounts[key])/numEntries\n",
    "        # 计算香农熵，以 2 为底求对数\n",
    "        shannonEnt -= prob * math.log(prob, 2)\n",
    "    return shannonEnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = calcShannonEnt(myDat)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照给定特征划分数据集\n",
    "def splitDataSet(dataSet, index, value):\n",
    "    \"\"\"splitDataSet(通过遍历dataSet数据集，求出index对应的colnum列的值为value的行)\n",
    "        就是依据index列进行分类，如果index列的数据等于 value的时候，就要将 index 划分到我们创建的新的数据集中\n",
    "    Args:\n",
    "        dataSet 数据集                 待划分的数据集\n",
    "        index 表示每一行的index列        划分数据集的特征\n",
    "        value 表示index列对应的value值   需要返回的特征的值。\n",
    "    Returns:\n",
    "        index列为value的数据集【该数据集需要排除index列】\n",
    "    \"\"\"\n",
    "    retDataSet = []\n",
    "    for featVec in dataSet: \n",
    "        # index列为value的数据集【该数据集需要排除index列】\n",
    "        # 判断index列的值是否为value\n",
    "        if featVec[index] == value:\n",
    "            # chop out index used for splitting\n",
    "            # [:index]表示前index行，即若 index 为2，就是取 featVec 的前 index 行\n",
    "            reducedFeatVec = featVec[:index]\n",
    "            '''\n",
    "            请百度查询一下： extend和append的区别\n",
    "            music_media.append(object) 向列表中添加一个对象object\n",
    "            music_media.extend(sequence) 把一个序列seq的内容添加到列表中 (跟 += 在list运用类似， music_media += sequence)\n",
    "            1、使用append的时候，是将object看作一个对象，整体打包添加到music_media对象中。\n",
    "            2、使用extend的时候，是将sequence看作一个序列，将这个序列和music_media序列合并，并放在其后面。\n",
    "            music_media = []\n",
    "            music_media.extend([1,2,3])\n",
    "            print music_media\n",
    "            #结果：\n",
    "            #[1, 2, 3]\n",
    "\n",
    "            music_media.append([4,5,6])\n",
    "            print music_media\n",
    "            #结果：\n",
    "            #[1, 2, 3, [4, 5, 6]]\n",
    "\n",
    "            music_media.extend([7,8,9])\n",
    "            print music_media\n",
    "            #结果：\n",
    "            #[1, 2, 3, [4, 5, 6], 7, 8, 9]\n",
    "            '''\n",
    "            reducedFeatVec.extend(featVec[index+1:])\n",
    "            # [index+1:]表示从跳过 index 的 index+1行，取接下来的数据\n",
    "            # 收集结果值 index列为value的行【该行需要排除index列】\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "    return retDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择最好的数据集划分方式\n",
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    \"\"\"chooseBestFeatureToSplit(选择最好的特征)\n",
    "\n",
    "    Args:\n",
    "        dataSet 数据集\n",
    "    Returns:\n",
    "        bestFeature 最优的特征列\n",
    "    \"\"\"\n",
    "    # 求第一行有多少列的 Feature, 最后一列是label列嘛\n",
    "    numFeatures = len(dataSet[0]) - 1\n",
    "    # 数据集的原始信息熵\n",
    "    baseEntropy = calcShannonEnt(dataSet)\n",
    "    # 最优的信息增益值, 和最优的Featurn编号\n",
    "    bestInfoGain, bestFeature = 0.0, -1\n",
    "    # iterate over all the features\n",
    "    for i in range(numFeatures):\n",
    "        # create a list of all the examples of this feature\n",
    "        # 获取对应的feature下的所有数据\n",
    "        featList = [example[i] for example in dataSet]\n",
    "        # get a set of unique values\n",
    "        # 获取剔重后的集合，使用set对list数据进行去重\n",
    "        uniqueVals = set(featList)\n",
    "        # 创建一个临时的信息熵\n",
    "        newEntropy = 0.0\n",
    "        # 遍历某一列的value集合，计算该列的信息熵 \n",
    "        # 遍历当前特征中的所有唯一属性值，对每个唯一属性值划分一次数据集，计算数据集的新熵值，并对所有唯一特征值得到的熵求和。\n",
    "        for value in uniqueVals:\n",
    "            subDataSet = splitDataSet(dataSet, i, value)\n",
    "            # 计算概率\n",
    "            prob = len(subDataSet)/float(len(dataSet))\n",
    "            # 计算信息熵\n",
    "            newEntropy += prob * calcShannonEnt(subDataSet)\n",
    "        # gain[信息增益]: 划分数据集前后的信息变化， 获取信息熵最大的值\n",
    "        # 信息增益是熵的减少或者是数据无序度的减少。最后，比较所有特征中的信息增益，返回最好特征划分的索引值。\n",
    "        infoGain = baseEntropy - newEntropy\n",
    "        print ('infoGain=', infoGain, 'bestFeature=', i, baseEntropy, newEntropy)\n",
    "        if (infoGain > bestInfoGain):\n",
    "            bestInfoGain = infoGain\n",
    "            bestFeature = i\n",
    "    return bestFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infoGain= 0.4199730940219749 bestFeature= 0 0.9709505944546686 0.5509775004326937\n",
      "infoGain= 0.17095059445466854 bestFeature= 1 0.9709505944546686 0.8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestFeature = chooseBestFeatureToSplit(myDat)\n",
    "bestFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练算法：构造树的数据结构\n",
    "def createTree(dataSet, labels):\n",
    "    classList = [example[-1] for example in dataSet]\n",
    "    # 如果数据集的最后一列的第一个值出现的次数=整个集合的数量，也就说只有一个类别，就只直接返回结果就行\n",
    "    # 第一个停止条件：所有的类标签完全相同，则直接返回该类标签。\n",
    "    # count() 函数是统计括号中的值在list中出现的次数\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        return classList[0]\n",
    "    # 如果数据集只有1列，那么最初出现label次数最多的一类，作为结果\n",
    "    # 第二个停止条件：使用完了所有特征，仍然不能将数据集划分成仅包含唯一类别的分组。\n",
    "    if len(dataSet[0]) == 1:\n",
    "        return majorityCnt(classList)\n",
    "\n",
    "    # 选择最优的列，得到最优列对应的label含义\n",
    "    bestFeat = chooseBestFeatureToSplit(dataSet)\n",
    "    # 获取label的名称\n",
    "    bestFeatLabel = labels[bestFeat]\n",
    "    # 初始化myTree\n",
    "    myTree = {bestFeatLabel: {}}\n",
    "    # 注：labels列表是可变对象，在PYTHON函数中作为参数时传址引用，能够被全局修改\n",
    "    # 所以这行代码导致函数外的同名变量被删除了元素，造成例句无法执行，提示'no surfacing' is not in list\n",
    "    del(labels[bestFeat])\n",
    "    # 取出最优列，然后它的branch做分类\n",
    "    featValues = [example[bestFeat] for example in dataSet]\n",
    "    uniqueVals = set(featValues)\n",
    "    for value in uniqueVals:\n",
    "        # 求出剩余的标签label\n",
    "        subLabels = labels[:]\n",
    "        # 遍历当前选择特征包含的所有属性值，在每个数据集划分上递归调用函数createTree()\n",
    "        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value), subLabels)\n",
    "        # print 'myTree', value, myTree\n",
    "    return myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infoGain= 0.4199730940219749 bestFeature= 0 0.9709505944546686 0.5509775004326937\n",
      "infoGain= 0.17095059445466854 bestFeature= 1 0.9709505944546686 0.8\n",
      "infoGain= 0.9182958340544896 bestFeature= 0 0.9182958340544896 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "myTree = createTree(myDat, copy.deepcopy(labels))\n",
    "myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试算法：使用决策树执行分类\n",
    "def classify(inputTree, featLabels, testVec):\n",
    "    \"\"\"classify(给输入的节点，进行分类)\n",
    "\n",
    "    Args:\n",
    "        inputTree  决策树模型\n",
    "        featLabels Feature标签对应的名称\n",
    "        testVec    测试输入的数据\n",
    "    Returns:\n",
    "        classLabel 分类的结果值，需要映射label才能知道名称\n",
    "    \"\"\"\n",
    "    # 获取tree的根节点对于的key值\n",
    "    firstStr = list(inputTree.keys())[0]\n",
    "    # 通过key得到根节点对应的value\n",
    "    secondDict = inputTree[firstStr]\n",
    "    # 判断根节点名称获取根节点在label中的先后顺序，这样就知道输入的testVec怎么开始对照树来做分类\n",
    "    featIndex = featLabels.index(firstStr)\n",
    "    # 测试数据，找到根节点对应的label位置，也就知道从输入的数据的第几位来开始分类\n",
    "    key = testVec[featIndex]\n",
    "    valueOfFeat = secondDict[key]\n",
    "    print ('+++', firstStr, 'xxx', secondDict, '---', key, '>>>', valueOfFeat)\n",
    "    # 判断分枝是否结束: 判断valueOfFeat是否是dict类型\n",
    "    if isinstance(valueOfFeat, dict):\n",
    "        classLabel = classify(valueOfFeat, featLabels, testVec)\n",
    "    else:\n",
    "        classLabel = valueOfFeat\n",
    "    return classLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ no surfacing xxx {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}} --- 0 >>> no\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classLabel = classify(myTree, labels, [0, 0])\n",
    "classLabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 项目案例2: 使用决策树预测隐形眼镜类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infoGain= 0.03939650364612124 bestFeature= 0 1.3260875253642983 1.286691021718177\n",
      "infoGain= 0.039510835423565815 bestFeature= 1 1.3260875253642983 1.2865766899407325\n",
      "infoGain= 0.37700523001147723 bestFeature= 2 1.3260875253642983 0.9490822953528211\n",
      "infoGain= 0.5487949406953986 bestFeature= 3 1.3260875253642983 0.7772925846688997\n",
      "infoGain= 0.22125183600446618 bestFeature= 0 1.5545851693377994 1.3333333333333333\n",
      "infoGain= 0.09543725231055489 bestFeature= 1 1.5545851693377994 1.4591479170272446\n",
      "infoGain= 0.7704260414863776 bestFeature= 2 1.5545851693377994 0.7841591278514218\n",
      "infoGain= 0.2516291673878229 bestFeature= 0 0.9182958340544896 0.6666666666666666\n",
      "infoGain= 0.4591479170272448 bestFeature= 1 0.9182958340544896 0.4591479170272448\n",
      "infoGain= 0.9182958340544896 bestFeature= 0 0.9182958340544896 0.0\n",
      "infoGain= 0.3166890883150208 bestFeature= 0 0.6500224216483541 0.3333333333333333\n",
      "infoGain= 0.19087450462110933 bestFeature= 1 0.6500224216483541 0.4591479170272448\n",
      "infoGain= 1.0 bestFeature= 0 1.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tearRate': {'reduced': 'no lenses',\n",
       "  'normal': {'astigmatic': {'yes': {'prescript': {'hyper': {'age': {'young': 'hard',\n",
       "        'pre': 'no lenses',\n",
       "        'presbyopic': 'no lenses'}},\n",
       "      'myope': 'hard'}},\n",
       "    'no': {'age': {'young': 'soft',\n",
       "      'pre': 'soft',\n",
       "      'presbyopic': {'prescript': {'hyper': 'soft',\n",
       "        'myope': 'no lenses'}}}}}}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载隐形眼镜相关的 文本文件 数据\n",
    "fr = open('./lenses.txt')\n",
    "# 解析数据，获得 features 数据\n",
    "lenses = [inst.strip().split('\\t') for inst in fr.readlines()]\n",
    "# 得到数据的对应的 Labels\n",
    "lensesLabels = ['age', 'prescript', 'astigmatic', 'tearRate']\n",
    "# 使用上面的创建决策树的代码，构造预测隐形眼镜的决策树\n",
    "lensesTree = createTree(lenses, lensesLabels)\n",
    "lensesTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
