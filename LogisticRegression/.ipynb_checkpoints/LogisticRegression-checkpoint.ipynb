{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 项目案例1: 使用 Logistic 回归在简单数据集上的分类\n",
    "完整代码地址: https://github.com/apachecn/AiLearning/blob/master/src/py3.x/ml/5.Logistic/logistic.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解析数据\n",
    "def loadDataSet(file_name):\n",
    "    '''\n",
    "    Desc: \n",
    "        加载并解析数据\n",
    "    Args:\n",
    "        file_name -- 要解析的文件路径\n",
    "    Returns:\n",
    "        dataMat -- 原始数据的特征\n",
    "        labelMat -- 原始数据的标签，也就是每条样本对应的类别。即目标向量\n",
    "    '''\n",
    "    # dataMat为原始数据， labelMat为原始数据的标签\n",
    "    dataMat = []\n",
    "    labelMat = []\n",
    "    fr = open(file_name)\n",
    "    for line in fr.readlines():\n",
    "        lineArr = line.strip().split()\n",
    "        # 为了方便计算，我们将 X0 的值设为 1.0 ，也就是在每一行的开头添加一个 1.0 作为 X0\n",
    "        dataMat.append([1.0, float(lineArr[0]), float(lineArr[1])])\n",
    "        labelMat.append(int(lineArr[2]))\n",
    "    return dataMat, labelMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1.0, -0.017612, 14.053064],\n",
       " [1.0, -1.395634, 4.662541],\n",
       " [1.0, -0.752157, 6.53862],\n",
       " [1.0, -1.322371, 7.152853],\n",
       " [1.0, 0.423363, 11.054677]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_arr, class_labels = loadDataSet(r'./TestSet.txt')\n",
    "print(class_labels)\n",
    "data_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid阶跃函数\n",
    "import math\n",
    "def sigmoid(inX):\n",
    "    # return 1.0 / (1 + exp(-inX))\n",
    "\n",
    "    # Tanh是Sigmoid的变形，与 sigmoid 不同的是，tanh 是0均值的。因此，实际应用中，tanh 会比 sigmoid 更好。\n",
    "    return 2 * 1.0/(1+math.exp(-2*inX)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = sigmoid(0)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic 回归梯度上升优化算法\n",
    "\n",
    "# 正常的处理方案\n",
    "# 两个参数：第一个参数==> dataMatIn 是一个2维NumPy数组，每列分别代表每个不同的特征，每行则代表每个训练样本。\n",
    "# 第二个参数==> classLabels 是类别标签，它是一个 1*100 的行向量。为了便于矩阵计算，需要将该行向量转换为列向量，做法是将原向量转置，再将它赋值给labelMat。\n",
    "def gradAscent(dataMatIn, classLabels):\n",
    "    # 转化为矩阵[[1,1,2],[1,1,2]....]\n",
    "    dataMatrix = mat(dataMatIn)             # 转换为 NumPy 矩阵\n",
    "    # 转化为矩阵[[0,1,0,1,0,1.....]]，并转制[[0],[1],[0].....]\n",
    "    # transpose() 行列转置函数\n",
    "    # 将行向量转化为列向量   =>  矩阵的转置\n",
    "    labelMat = mat(classLabels).transpose() # 首先将数组转换为 NumPy 矩阵，然后再将行向量转置为列向量\n",
    "    # m->数据量，样本数 n->特征数\n",
    "    m,n = shape(dataMatrix)\n",
    "    # print m, n, '__'*10, shape(dataMatrix.transpose()), '__'*100\n",
    "    # alpha代表向目标移动的步长\n",
    "    alpha = 0.001\n",
    "    # 迭代次数\n",
    "    maxCycles = 500\n",
    "    # 生成一个长度和特征数相同的矩阵，此处n为3 -> [[1],[1],[1]]\n",
    "    # weights 代表回归系数， 此处的 ones((n,1)) 创建一个长度和特征数相同的矩阵，其中的数全部都是 1\n",
    "    weights = ones((n,1))\n",
    "    for k in range(maxCycles):              #heavy on matrix operations\n",
    "        # m*3 的矩阵 * 3*1 的矩阵 ＝ m*1的矩阵\n",
    "        # 那么乘上矩阵的意义，就代表：通过公式得到的理论值\n",
    "        # 参考地址： 矩阵乘法的本质是什么？ https://www.zhihu.com/question/21351965/answer/31050145\n",
    "        # print 'dataMatrix====', dataMatrix \n",
    "        # print 'weights====', weights\n",
    "        # n*3   *  3*1  = n*1\n",
    "        h = sigmoid(dataMatrix*weights)     # 矩阵乘法\n",
    "        # print 'hhhhhhh====', h\n",
    "        # labelMat是实际值\n",
    "        error = (labelMat - h)              # 向量相减\n",
    "        # 0.001* (3*m)*(m*1) 表示在每一个列上的一个误差情况，最后得出 x1,x2,xn的系数的偏移量\n",
    "        weights = weights + alpha * dataMatrix.transpose() * error # 矩阵乘法，最后得到回归系数\n",
    "    return array(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画出数据集和 Logistic 回归最佳拟合直线的函数\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotBestFit(dataArr, labelMat, weights):\n",
    "    '''\n",
    "        Desc:\n",
    "            将我们得到的数据可视化展示出来\n",
    "        Args:\n",
    "            dataArr:样本数据的特征\n",
    "            labelMat:样本数据的类别标签，即目标变量\n",
    "            weights:回归系数\n",
    "        Returns:\n",
    "            None\n",
    "    '''\n",
    "\n",
    "    n = shape(dataArr)[0]\n",
    "    xcord1 = []; ycord1 = []\n",
    "    xcord2 = []; ycord2 = []\n",
    "    for i in range(n):\n",
    "        if int(labelMat[i])== 1:\n",
    "            xcord1.append(dataArr[i,1]); ycord1.append(dataArr[i,2])\n",
    "        else:\n",
    "            xcord2.append(dataArr[i,1]); ycord2.append(dataArr[i,2])\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(xcord1, ycord1, s=30, c='red', marker='s')\n",
    "    ax.scatter(xcord2, ycord2, s=30, c='green')\n",
    "    x = arange(-3.0, 3.0, 0.1)\n",
    "    \"\"\"\n",
    "    y的由来，卧槽，是不是没看懂？\n",
    "    首先理论上是这个样子的。\n",
    "    dataMat.append([1.0, float(lineArr[0]), float(lineArr[1])])\n",
    "    w0*x0+w1*x1+w2*x2=f(x)\n",
    "    x0最开始就设置为1叻， x2就是我们画图的y值，而f(x)被我们磨合误差给算到w0,w1,w2身上去了\n",
    "    所以： w0+w1*x+w2*y=0 => y = (-w0-w1*x)/w2   \n",
    "    \"\"\"\n",
    "    y = (-weights[0]-weights[1]*x)/weights[2]\n",
    "    ax.plot(x, y)\n",
    "    plt.xlabel('X'); plt.ylabel('Y')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.      , -0.017612, 14.053064],\n",
       "       [ 1.      , -1.395634,  4.662541],\n",
       "       [ 1.      , -0.752157,  6.53862 ],\n",
       "       [ 1.      , -1.322371,  7.152853],\n",
       "       [ 1.      ,  0.423363, 11.054677]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1.收集并准备数据\n",
    "dataMat, labelMat = loadDataSet(r'./TestSet.txt')\n",
    "dataMat\n",
    "# print dataMat, '---\\n', labelMat\n",
    "# 2.训练模型，  f(x)=a1*x1+b2*x2+..+nn*xn中 (a1,b2, .., nn).T的矩阵值\n",
    "# 因为数组没有是复制n份， array的乘法就是乘法\n",
    "dataArr = np.array(dataMat)\n",
    "# dataArr\n",
    "# print dataArr\n",
    "# weights = gradAscent(dataArr, labelMat)\n",
    "# weights = stocGradAscent0(dataArr, labelMat)\n",
    "# weights = stocGradAscent1(dataArr, labelMat)\n",
    "# print '*'*30, weights\n",
    "\n",
    "# 数据可视化\n",
    "# plotBestFit(dataArr, labelMat, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
