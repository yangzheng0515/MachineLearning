{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入相关数据包\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv('./data/output/data_transform_outV2/part-00000', sep=',', \n",
    "                   names = [\"device_id\", \"vc_id\", \"vd_id\", \n",
    "                            \"net_droppedTx_summation\", \n",
    "                            \"net_packetsTx_summation\", \n",
    "                            \"virtualDisk_numberReadAveraged_average\", \n",
    "                            \"virtualDisk_numberWriteAveraged_average\",\n",
    "                            \"virtualDisk_write_average\",\n",
    "                            \"virtualDisk_read_average\",\n",
    "                            \"datastore_maxTotalLatency_latest\",\n",
    "                            \"cpu_usage_average\",\n",
    "                            \"mem_usage_average\",\n",
    "                            \"net_usage_average\",\n",
    "                            \"net_packetsRx_summation\",\n",
    "                            \"net_droppedRx_summation\",\n",
    "                            \"net_bytesRx_average\",\n",
    "                            \"net_bytesTx_average\",\n",
    "                            \"time\",\n",
    "                            \"date\"\n",
    "                           ])\n",
    "\n",
    "for i in range(1, 7):\n",
    "    file_path = './data/output/data_transform_outV2/part-0000{}'.format(i)\n",
    "    d = pd.read_csv(file_path, sep=',', \n",
    "                   names = [\"device_id\", \"vc_id\", \"vd_id\", \n",
    "                            \"net_droppedTx_summation\", \n",
    "                            \"net_packetsTx_summation\", \n",
    "                            \"virtualDisk_numberReadAveraged_average\", \n",
    "                            \"virtualDisk_numberWriteAveraged_average\",\n",
    "                            \"virtualDisk_write_average\",\n",
    "                            \"virtualDisk_read_average\",\n",
    "                            \"datastore_maxTotalLatency_latest\",\n",
    "                            \"cpu_usage_average\",\n",
    "                            \"mem_usage_average\",\n",
    "                            \"net_usage_average\",\n",
    "                            \"net_packetsRx_summation\",\n",
    "                            \"net_droppedRx_summation\",\n",
    "                            \"net_bytesRx_average\",\n",
    "                            \"net_bytesTx_average\",\n",
    "                            \"time\",\n",
    "                            \"date\"\n",
    "                           ])\n",
    "    data = data.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_2400 = data.loc[data['device_id'] == 2400]\n",
    "device_2400 = device_2400.reset_index().drop('index', axis=1)\n",
    "device_2400 = device_2400.drop('device_id', axis=1).drop('vc_id', axis=1).drop('vd_id', axis=1).drop('time', axis=1)\n",
    "device_2400_day = device_2400.groupby(['date']).sum()\n",
    "index = device_2400_day.index\n",
    "device_2400_day.index = np.arange(device_2400_day.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date2num(dates):\n",
    "    indexs = []\n",
    "    for d in dates:\n",
    "        month = int(d.split('-')[1])\n",
    "        day = int(d.split('-')[2])\n",
    "        if month == 9:\n",
    "            num = day\n",
    "        elif month == 10:\n",
    "            num = day+30\n",
    "        elif month == 11:\n",
    "            num = day+61\n",
    "        indexs.append(num-15)\n",
    "    return indexs\n",
    "\n",
    "nums = date2num(index)\n",
    "device_2400_day['dateNum'] = nums\n",
    "\n",
    "label = []\n",
    "for d in device_2400_day['dateNum']:\n",
    "    if d > 50: label.append(1)\n",
    "    else: label.append(0)\n",
    "device_2400_day['lable'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_7361 = data.loc[data['device_id'] == 7361]\n",
    "device_7363 = data.loc[data['device_id'] == 7363]\n",
    "\n",
    "device_7361 = device_7361.reset_index().drop('index', axis=1)\n",
    "device_7361 = device_7361.drop('device_id', axis=1).drop('vc_id', axis=1).drop('vd_id', axis=1).drop('time', axis=1)\n",
    "\n",
    "device_7363 = device_7363.reset_index().drop('index', axis=1)\n",
    "device_7363 = device_7363.drop('device_id', axis=1).drop('vc_id', axis=1).drop('vd_id', axis=1).drop('time', axis=1)\n",
    "\n",
    "device_7361_day = device_7361.groupby(['date']).sum()\n",
    "\n",
    "device_7363_day = device_7361.groupby(['date']).sum()\n",
    "\n",
    "device_7361_day['dateNum'] = nums\n",
    "\n",
    "device_7363_day['dateNum'] = nums\n",
    "\n",
    "device_7361_day['lable'] = label\n",
    "\n",
    "device_7363_day['lable'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = device_2400_day.append(device_7361_day)\n",
    "train_data.index = np.arange(train_data.shape[0])\n",
    "\n",
    "test_data = device_7363_day\n",
    "test_data.index = np.arange(test_data.shape[0])\n",
    "\n",
    "train_data_X = train_data.drop(['lable'],axis=1)\n",
    "train_data_Y = train_data['lable']\n",
    "test_data_X = test_data.drop(['lable'],axis=1)\n",
    "test_data_Y = test_data['lable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "need_drop_feature = ['net_droppedTx_summation',\n",
    "                    'virtualDisk_numberReadAveraged_average', \n",
    "                    'virtualDisk_numberWriteAveraged_average', \n",
    "                    'virtualDisk_write_average',\n",
    "                    'virtualDisk_read_average', \n",
    "                    'datastore_maxTotalLatency_latest', \n",
    "                    'net_droppedRx_summation', \n",
    "                    'dateNum']\n",
    "\n",
    "for f in need_drop_feature:\n",
    "    train_data_X = train_data_X.drop([f], axis=1)\n",
    "    test_data_X = test_data_X.drop([f], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122, 16)\n",
      "(61, 16)\n",
      "(122, 7)\n",
      "(61, 7)\n"
     ]
    }
   ],
   "source": [
    "# train_data_X.head()\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(train_data_X.shape)\n",
    "print(test_data_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBDT\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbdt = GradientBoostingClassifier(learning_rate=0.7,max_depth=6,n_estimators=100,min_samples_leaf=2)\n",
    "\n",
    "gbdt.fit(train_data_X,train_data_Y)\n",
    "\n",
    "test_data[\"predict\"] = gbdt.predict(test_data_X)\n",
    "test_data.to_csv('gbdtTest2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1.Loading data...\n",
      "---Loading and splitting completed.\n",
      "Step 2.Training...\n",
      "---Training Completed.Took 0.003004 s.\n",
      "Step 3.Testing...\n",
      "---Testing completed.Accuracy: 100.000%\n",
      "Visible tree plot saved as pdf.\n"
     ]
    }
   ],
   "source": [
    "# !/usr/bin/env python3\n",
    "# coding=utf-8\n",
    "\"\"\"\n",
    "Decision Tree on the Basis of sklearn module\n",
    "Author  :Chai Zheng\n",
    "Blog    :http://blog.csdn.net/chai_zheng/\n",
    "Github  :https://github.com/Chai-Zheng/Machine-Learning\n",
    "Email   :zchaizju@gmail.com\n",
    "Date    :2017.10.13\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pydotplus\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.externals.six import StringIO\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print('Step 1.Loading data...')\n",
    "X_train,X_test,Y_train,Y_test = train_data_X, test_data_X, train_data_Y, test_data_Y\n",
    "print('---Loading and splitting completed.')\n",
    "\n",
    "print('Step 2.Training...')\n",
    "startTime = time.time()\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train,Y_train)\n",
    "print('---Training Completed.Took %f s.'%(time.time()-startTime))\n",
    "\n",
    "print('Step 3.Testing...')\n",
    "Y_predict = clf.predict(X_test)\n",
    "matchCount = 0\n",
    "for i in range(len(Y_predict)):\n",
    "    if Y_predict[i] == Y_test[i]:\n",
    "        matchCount += 1\n",
    "accuracy = float(matchCount/len(Y_predict))\n",
    "print('---Testing completed.Accuracy: %.3f%%'%(accuracy*100))\n",
    "\n",
    "feature_name = [ #\"net_droppedTx_summation\", \n",
    "                            \"net_packetsTx_summation\", \n",
    "#                             \"virtualDisk_numberReadAveraged_average\", \n",
    "#                             \"virtualDisk_numberWriteAveraged_average\",\n",
    "#                             \"virtualDisk_write_average\",\n",
    "#                             \"virtualDisk_read_average\",\n",
    "#                             \"datastore_maxTotalLatency_latest\",\n",
    "                            \"cpu_usage_average\",\n",
    "                            \"mem_usage_average\",\n",
    "                            \"net_usage_average\",\n",
    "                            \"net_packetsRx_summation\",\n",
    "#                             \"net_droppedRx_summation\",\n",
    "                            \"net_bytesRx_average\",\n",
    "                            \"net_bytesTx_average\"\n",
    "                           ]\n",
    "target_name = ['Class0', 'Class1']\n",
    "\n",
    "dot_data = StringIO()\n",
    "tree.export_graphviz(clf,out_file = dot_data,feature_names=feature_name,\n",
    "                     class_names=target_name,filled=True,rounded=True,\n",
    "                     special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "graph.write_pdf(\"WineTree2.pdf\")\n",
    "print('Visible tree plot saved as pdf.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_predict = clf.predict(X_test)\n",
    "Y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "sample0 = pd.DataFrame([[79397399.0, 195588.0, 304122.0, 9992298.0, 89428553.0, 873397.0, 2456465.0]])\n",
    "sample1 = pd.DataFrame([[1465851.0, 20583.0, 301541.0, 595662.0, 1786858.0, 32061.0, 165232.0]])\n",
    "predict0 = clf.predict(sample0)\n",
    "predict1 = clf.predict(sample1)\n",
    "print(predict0[0])\n",
    "print(predict1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "sample1 = [79397399.0, 195588.0, 304122.0, 9992298.0, 89428553.0, 873397.0, 2456465.0]\n",
    "sample2 = [1465851.0, 20583.0, 301541.0, 595662.0, 1786858.0, 32061.0, 165232.0]\n",
    "samples = pd.DataFrame([sample1, sample2])\n",
    "predicts = clf.predict(samples)\n",
    "print(predicts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
